{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da00927",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><strong>Don-Moses Chiemela</strong><br>\n",
    "<strong>Classification Model Development</strong>\n",
    "\n",
    "<br> Dataset: Game of thrones characters\n",
    "<br><br>\n",
    "First I'll import all required libraries.\n",
    "Next I'll load the dataset, set print output options and preview the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c30c9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>culture</th>\n",
       "      <th>dateOfBirth</th>\n",
       "      <th>mother</th>\n",
       "      <th>father</th>\n",
       "      <th>heir</th>\n",
       "      <th>house</th>\n",
       "      <th>spouse</th>\n",
       "      <th>book1_A_Game_Of_Thrones</th>\n",
       "      <th>book2_A_Clash_Of_Kings</th>\n",
       "      <th>book3_A_Storm_Of_Swords</th>\n",
       "      <th>book4_A_Feast_For_Crows</th>\n",
       "      <th>book5_A_Dance_with_Dragons</th>\n",
       "      <th>isAliveMother</th>\n",
       "      <th>isAliveFather</th>\n",
       "      <th>isAliveHeir</th>\n",
       "      <th>isAliveSpouse</th>\n",
       "      <th>isMarried</th>\n",
       "      <th>isNoble</th>\n",
       "      <th>age</th>\n",
       "      <th>numDeadRelations</th>\n",
       "      <th>popularity</th>\n",
       "      <th>isAlive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Viserys II Targaryen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rhaenyra Targaryen</td>\n",
       "      <td>Daemon Targaryen</td>\n",
       "      <td>Aegon IV Targaryen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>0.605351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Walder Frey</td>\n",
       "      <td>Lord of the Crossing</td>\n",
       "      <td>Rivermen</td>\n",
       "      <td>208.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Frey</td>\n",
       "      <td>Perra Royce</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Addison Hill</td>\n",
       "      <td>Ser</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Swyft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.267559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Aemma Arryn</td>\n",
       "      <td>Queen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Arryn</td>\n",
       "      <td>Viserys I Targaryen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.183946</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Sylva Santagar</td>\n",
       "      <td>Greenstone</td>\n",
       "      <td>Dornish</td>\n",
       "      <td>276.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Santagar</td>\n",
       "      <td>Eldon Estermont</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No                  name                 title   culture  dateOfBirth              mother            father                heir           house               spouse  book1_A_Game_Of_Thrones  book2_A_Clash_Of_Kings  book3_A_Storm_Of_Swords  book4_A_Feast_For_Crows  book5_A_Dance_with_Dragons  isAliveMother  isAliveFather  isAliveHeir  isAliveSpouse  isMarried  isNoble   age  numDeadRelations  popularity  isAlive\n",
       "0     1  Viserys II Targaryen                   NaN       NaN          NaN  Rhaenyra Targaryen  Daemon Targaryen  Aegon IV Targaryen             NaN                  NaN                        0                       0                        0                        0                           0            1.0            0.0          0.0            NaN          0        0   NaN                11    0.605351        0\n",
       "1     2           Walder Frey  Lord of the Crossing  Rivermen        208.0                 NaN               NaN                 NaN      House Frey          Perra Royce                        1                       1                        1                        1                           1            NaN            NaN          NaN            1.0          1        1  97.0                 1    0.896321        1\n",
       "2     3          Addison Hill                   Ser       NaN          NaN                 NaN               NaN                 NaN     House Swyft                  NaN                        0                       0                        0                        1                           0            NaN            NaN          NaN            NaN          0        1   NaN                 0    0.267559        1\n",
       "3     4           Aemma Arryn                 Queen       NaN         82.0                 NaN               NaN                 NaN     House Arryn  Viserys I Targaryen                        0                       0                        0                        0                           0            NaN            NaN          NaN            0.0          1        1  23.0                 0    0.183946        0\n",
       "4     5        Sylva Santagar            Greenstone   Dornish        276.0                 NaN               NaN                 NaN  House Santagar      Eldon Estermont                        0                       0                        0                        1                           0            NaN            NaN          NaN            1.0          1        1  29.0                 0    0.043478        1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Introduction:\n",
    "        Goal: To predict if the characters are alive or dead according to the story.\n",
    "     \n",
    "    Note:   All files are in the same folder (Script and Dataset - Excel file)\n",
    "            \n",
    "    \n",
    "    Known bugs: None\n",
    "\"\"\"\n",
    "\n",
    "# importing libraries\n",
    "import pandas            as pd                       # data science essentials\n",
    "import matplotlib.pyplot as plt                      # data visualization\n",
    "import seaborn           as sns                      # enhanced data viz\n",
    "from sklearn.model_selection import train_test_split # train-test split\n",
    "from sklearn.linear_model import LogisticRegression  # logistic regression\n",
    "import statsmodels.formula.api as smf                # logistic regression\n",
    "from sklearn.metrics import confusion_matrix         # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score            # auc score\n",
    "from sklearn.neighbors import KNeighborsClassifier   # KNN for classification\n",
    "from sklearn.preprocessing import StandardScaler     # standard scaler\n",
    "from sklearn.tree import DecisionTreeClassifier      # classification trees\n",
    "from sklearn.tree import plot_tree                   # tree plots\n",
    "import gender_guesser.detector as gender             # guess gender based on (given) name\n",
    "from sklearn.model_selection import RandomizedSearchCV # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer                # customizable scorer\n",
    "from sklearn.ensemble import RandomForestClassifier     # random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gbm\n",
    "\n",
    "# loading data\n",
    "file = 'GOT_character_predictions.xlsx'\n",
    "got = pd.read_excel(file)\n",
    "\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "\n",
    "# displaying the head of the dataset\n",
    "got.head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe684bb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br><strong>Feature Engineering</strong>\n",
    "\n",
    "<br>In order to understand the data, I will add a new feature - Gender\n",
    "\n",
    "<br>First I'll split the names to extract the first names using a for loop and split function. \n",
    "<br>Next I'll convert my list to a data frame and drop unwanted columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ee18a04",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Viserys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Addison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sylva</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "0  Viserys\n",
       "1   Walder\n",
       "2  Addison\n",
       "3    Aemma\n",
       "4    Sylva"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 1: splitting the character names emails\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping over each name in data frame\n",
    "for index, col in got.iterrows():\n",
    "\n",
    "    # splitting email domain at ' ' which is default\n",
    "    split_name = got.loc[index, 'name'].split()\n",
    "\n",
    "    # appending placeholder_lst with the results\n",
    "    placeholder_lst.append(split_name)\n",
    "\n",
    "# converting placeholder_lst into a DataFrame\n",
    "name_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "#droping unwanted columns\n",
    "name_df = name_df.drop(5, axis=1)\n",
    "name_df = name_df.drop(4, axis=1)\n",
    "name_df = name_df.drop(3, axis=1)\n",
    "name_df = name_df.drop(2, axis=1)\n",
    "name_df = name_df.drop(1, axis=1)\n",
    "\n",
    "# displaying the results and checking consistency\n",
    "name_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83095b75",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>Then i will run gender guesser to determine the gender using a library of baby names.\n",
    "\n",
    "<br> Result was copied and saved in a list in order to reduce processing time on the next run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b449834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # guessing gender based on first name\n",
    "# placeholder_gen = []\n",
    "# # looping to guess gender\n",
    "# for name in name_df[0]:\n",
    "#     guess = gender.Detector().get_gender(name)\n",
    "#    #print(guess)\n",
    "#     placeholder_gen.append(guess)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # checking results\n",
    "# print(placeholder_gen)\n",
    "\n",
    "gender_copy = ['unknown', 'unknown', 'andy', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'male', 'mostly_male', 'mostly_male', 'mostly_male', 'mostly_male', 'mostly_male', 'mostly_male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'female', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'male', 'andy', 'andy', 'unknown', 'andy', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'male', 'unknown', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'mostly_male', 'male', 'mostly_male', 'mostly_male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'mostly_male', 'unknown', 'unknown', 'male', 'female', 'andy', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'andy', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'female', 'female', 'female', 'female', 'female', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'mostly_female', 'female', 'unknown', 'mostly_female', 'unknown', 'female', 'unknown', 'female', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'andy', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'female', 'female', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', 'female', 'male', 'male', 'male', 'female', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'male', 'male', 'male', 'female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'andy', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'male', 'unknown', 'unknown', 'female', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'female', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'female', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'female', 'female', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'mostly_female', 'mostly_female', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'male', 'male', 'male', 'male', 'unknown', 'female', 'female', 'female', 'unknown', 'mostly_male', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'female', 'male', 'female', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'unknown', 'male', 'unknown', 'unknown', 'mostly_female', 'male', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'male', 'male', 'female', 'mostly_female', 'female', 'mostly_female', 'mostly_female', 'mostly_female', 'mostly_female', 'mostly_female', 'mostly_female', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'female', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'mostly_male', 'unknown', 'female', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'female', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'mostly_male', 'male', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'female', 'female', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'male', 'male', 'andy', 'male', 'male', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'male', 'male', 'male', 'male', 'male', 'male', 'mostly_male', 'mostly_male', 'mostly_male', 'mostly_male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'male', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'mostly_female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'female', 'unknown', 'female', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'andy', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'mostly_male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'male', 'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec90c480",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>I'll convert the list into a data frame and explore the data making sure all rows are complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84695966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender       \n",
       "unknown          1385\n",
       "male              381\n",
       "female            125\n",
       "mostly_male        24\n",
       "mostly_female      21\n",
       "andy               10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using dataframe function to create a dataframe from our list\n",
    "gender = pd.DataFrame(gender_copy)\n",
    "\n",
    "#adding a column name\n",
    "gender.columns = [ 'gender']\n",
    "\n",
    "#using value count to inspect out new column\n",
    "gender.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d318bb0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>Combining the new column with the original data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3ad76a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>culture</th>\n",
       "      <th>dateOfBirth</th>\n",
       "      <th>mother</th>\n",
       "      <th>father</th>\n",
       "      <th>heir</th>\n",
       "      <th>house</th>\n",
       "      <th>spouse</th>\n",
       "      <th>book1_A_Game_Of_Thrones</th>\n",
       "      <th>book2_A_Clash_Of_Kings</th>\n",
       "      <th>book3_A_Storm_Of_Swords</th>\n",
       "      <th>book4_A_Feast_For_Crows</th>\n",
       "      <th>book5_A_Dance_with_Dragons</th>\n",
       "      <th>isAliveMother</th>\n",
       "      <th>isAliveFather</th>\n",
       "      <th>isAliveHeir</th>\n",
       "      <th>isAliveSpouse</th>\n",
       "      <th>isMarried</th>\n",
       "      <th>isNoble</th>\n",
       "      <th>age</th>\n",
       "      <th>numDeadRelations</th>\n",
       "      <th>popularity</th>\n",
       "      <th>isAlive</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Viserys II Targaryen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rhaenyra Targaryen</td>\n",
       "      <td>Daemon Targaryen</td>\n",
       "      <td>Aegon IV Targaryen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>0.605351</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Walder Frey</td>\n",
       "      <td>Lord of the Crossing</td>\n",
       "      <td>Rivermen</td>\n",
       "      <td>208.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Frey</td>\n",
       "      <td>Perra Royce</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Addison Hill</td>\n",
       "      <td>Ser</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Swyft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.267559</td>\n",
       "      <td>1</td>\n",
       "      <td>andy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Aemma Arryn</td>\n",
       "      <td>Queen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Arryn</td>\n",
       "      <td>Viserys I Targaryen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.183946</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Sylva Santagar</td>\n",
       "      <td>Greenstone</td>\n",
       "      <td>Dornish</td>\n",
       "      <td>276.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Santagar</td>\n",
       "      <td>Eldon Estermont</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No                  name                 title   culture  dateOfBirth              mother            father                heir           house               spouse  book1_A_Game_Of_Thrones  book2_A_Clash_Of_Kings  book3_A_Storm_Of_Swords  book4_A_Feast_For_Crows  book5_A_Dance_with_Dragons  isAliveMother  isAliveFather  isAliveHeir  isAliveSpouse  isMarried  isNoble   age  numDeadRelations  popularity  isAlive   gender\n",
       "0     1  Viserys II Targaryen                   NaN       NaN          NaN  Rhaenyra Targaryen  Daemon Targaryen  Aegon IV Targaryen             NaN                  NaN                        0                       0                        0                        0                           0            1.0            0.0          0.0            NaN          0        0   NaN                11    0.605351        0  unknown\n",
       "1     2           Walder Frey  Lord of the Crossing  Rivermen        208.0                 NaN               NaN                 NaN      House Frey          Perra Royce                        1                       1                        1                        1                           1            NaN            NaN          NaN            1.0          1        1  97.0                 1    0.896321        1  unknown\n",
       "2     3          Addison Hill                   Ser       NaN          NaN                 NaN               NaN                 NaN     House Swyft                  NaN                        0                       0                        0                        1                           0            NaN            NaN          NaN            NaN          0        1   NaN                 0    0.267559        1     andy\n",
       "3     4           Aemma Arryn                 Queen       NaN         82.0                 NaN               NaN                 NaN     House Arryn  Viserys I Targaryen                        0                       0                        0                        0                           0            NaN            NaN          NaN            0.0          1        1  23.0                 0    0.183946        0  unknown\n",
       "4     5        Sylva Santagar            Greenstone   Dornish        276.0                 NaN               NaN                 NaN  House Santagar      Eldon Estermont                        0                       0                        0                        1                           0            NaN            NaN          NaN            1.0          1        1  29.0                 0    0.043478        1   female"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using concat function to join the dataframes\n",
    "got_full = pd.concat([got, gender], axis = 1)\n",
    "got_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02076eb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br><strong>Missing Values</strong>\n",
    "<br> Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5034d686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S.No                             0\n",
       "name                             0\n",
       "title                         1008\n",
       "culture                       1269\n",
       "dateOfBirth                   1513\n",
       "mother                        1925\n",
       "father                        1920\n",
       "heir                          1923\n",
       "house                          427\n",
       "spouse                        1670\n",
       "book1_A_Game_Of_Thrones          0\n",
       "book2_A_Clash_Of_Kings           0\n",
       "book3_A_Storm_Of_Swords          0\n",
       "book4_A_Feast_For_Crows          0\n",
       "book5_A_Dance_with_Dragons       0\n",
       "isAliveMother                 1925\n",
       "isAliveFather                 1920\n",
       "isAliveHeir                   1923\n",
       "isAliveSpouse                 1670\n",
       "isMarried                        0\n",
       "isNoble                          0\n",
       "age                           1513\n",
       "numDeadRelations                 0\n",
       "popularity                       0\n",
       "isAlive                          0\n",
       "gender                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for missing values\n",
    "got_full.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156034fe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>From the cell above, columns title, culture, dateOfBirt, mother, father, heir,\n",
    "isAliveMother, isAliveFather, isAliveHeir, isAliveSpouse, age have over 50% of\n",
    "missing values. Attempting to impute missing values for these columns would alter\n",
    "our dataset. We would proceed without these features. We would only impute missing values for 'house'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "078b24aa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#Filling missing values \n",
    "fill = 'unknown'\n",
    "got_full['house'] = got_full['house'].fillna(fill)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467a85e3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>Dummies: \n",
    "We would create dummies for the gender column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfb92f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['S.No', 'name', 'title', 'culture', 'dateOfBirth', 'mother', 'father', 'heir', 'house', 'spouse', 'book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings', 'book3_A_Storm_Of_Swords', 'book4_A_Feast_For_Crows', 'book5_A_Dance_with_Dragons', 'isAliveMother', 'isAliveFather', 'isAliveHeir', 'isAliveSpouse', 'isMarried', 'isNoble', 'age', 'numDeadRelations', 'popularity', 'isAlive', 'gender', 'andy', 'female', 'male', 'mostly_female', 'mostly_male', 'unknown'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating dummies for gender\n",
    "gender_dummy = pd.get_dummies(got_full['gender'])\n",
    "\n",
    "# joining codings together\n",
    "got_full = got_full.join(other = [ gender_dummy])\n",
    "\n",
    "\n",
    "# checking results\n",
    "got_full.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c364aa1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br><strong>Explanatory variable sets</strong>\n",
    "<br>These are the features we would use to build our classification model. \n",
    "We have dropped columns with many missing values, 'male' column from the dummies, and our y variable - isAlive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be175007",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# explanatory variable sets\n",
    "########################################\n",
    "candidate_dict = {\n",
    "\n",
    "\n",
    "\n",
    " # significant variables only (set 1)\n",
    " 'select_1'   : [ 'book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings', \n",
    "             'book3_A_Storm_Of_Swords', 'book4_A_Feast_For_Crows', \n",
    "             'book5_A_Dance_with_Dragons','isMarried','isNoble','popularity',\n",
    "                   'numDeadRelations', 'andy', 'female', 'mostly_female', \n",
    "                 'mostly_male', 'unknown'],\n",
    "\n",
    "\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f13264a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>Checking the correlation between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d767fc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isAlive                       1.000\n",
       "isAliveHeir                   0.385\n",
       "book4_A_Feast_For_Crows       0.269\n",
       "isAliveFather                 0.196\n",
       "isAliveSpouse                 0.174\n",
       "age                           0.087\n",
       "female                        0.052\n",
       "book5_A_Dance_with_Dragons    0.033\n",
       "mostly_male                   0.012\n",
       "andy                          0.009\n",
       "book3_A_Storm_Of_Swords       0.007\n",
       "mostly_female                 0.004\n",
       "male                         -0.006\n",
       "unknown                      -0.028\n",
       "isNoble                      -0.042\n",
       "isAliveMother                -0.043\n",
       "isMarried                    -0.050\n",
       "book2_A_Clash_Of_Kings       -0.067\n",
       "dateOfBirth                  -0.086\n",
       "S.No                         -0.129\n",
       "book1_A_Game_Of_Thrones      -0.147\n",
       "popularity                   -0.183\n",
       "numDeadRelations             -0.192\n",
       "Name: isAlive, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking correlation with our y variable\n",
    "got_corr = got_full.corr().round(3)\n",
    "\n",
    "got_corr['isAlive'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e698fce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br><strong>Classification Models</strong>\n",
    "\n",
    "<br>We will begin our modeling. We would use 4 different classification models. \n",
    "<br><br>Creating a place holder for our model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55320ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary for model results\n",
    "model_performance = {\n",
    "    \n",
    "    'Model Name'    : [],\n",
    "           \n",
    "    'AUC Score' : [],\n",
    "    \n",
    "    'Training Accuracy' : [],\n",
    "           \n",
    "    'Testing Accuracy'  : [],\n",
    "\n",
    "    'Confusion Matrix'  : []}\n",
    "\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "model_performance = pd.DataFrame(model_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb61e22",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>Lets define our explanatory variable with the dictionary created previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "920be636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring explanatory variables\n",
    "got_data = got_full.loc[ : , candidate_dict['select_1']]\n",
    "\n",
    "\n",
    "# declaring response variable\n",
    "got_target = got_full.loc[ : , 'isAlive']\n",
    "\n",
    "# train-test split with stratification\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            got_data,\n",
    "            got_target,\n",
    "            test_size    = 0.10, #test sample size\n",
    "            random_state = 219,\n",
    "            stratify     = got_target) # preserving balance\n",
    "\n",
    "\n",
    "# merging training data for statsmodels\n",
    "got_train = pd.concat([x_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0181ed1f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br><strong>Logistic Regression</strong>\n",
    "\n",
    "<br>Using logistic regression, we will create a classification model using hyper tuning to determine best parameters. \n",
    "<br> Then we would comment our the hyper tuning portion so our code runs faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8176dafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################################\n",
    "# # RandomizedSearchCV\n",
    "# ########################################\n",
    "\n",
    "# # declaring a hyperparameter space\n",
    "# C_range          = np.arange(0.1, 35.0, 0.1)\n",
    "# warm_start_range = [True, False]\n",
    "# solver_range     = ['newton-cg', 'sag', 'lbfgs']\n",
    "# class_weight_range = [ dict, 'balanced', None]\n",
    "# max_iter_range           =np.arange(100, 200, 1)\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'C'           : C_range,\n",
    "#               'warm_start'  : warm_start_range,\n",
    "#               'solver'      : solver_range,\n",
    "#               'class_weight': class_weight_range,\n",
    "#               'max_iter'    : max_iter_range\n",
    "#              }\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# lr_tuned = LogisticRegression(random_state = 219,\n",
    "#                               max_iter     = 1000) # increased for convergence\n",
    "\n",
    "\n",
    "# # GridSearchCV object\n",
    "# lr_tuned_cv = RandomizedSearchCV(estimator           = lr_tuned,   # the model object\n",
    "#                                  param_distributions = param_grid, # parameters to tune\n",
    "#                                  cv                  = 3,          # how many folds in cross-validation\n",
    "#                                  n_iter              = 250,        # number of combinations of hyperparameters to try\n",
    "#                                  random_state        = 219,        # starting point for random sequence\n",
    "#                                  scoring = make_scorer(\n",
    "#                                            roc_auc_score,\n",
    "#                                            needs_threshold = False)) # scoring criteria (AUC)\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# lr_tuned_cv.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "# # PREDICT step is not needed\n",
    "\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", lr_tuned_cv.best_params_)\n",
    "# print(\"Tuned CV AUC      :\", lr_tuned_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a82025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checking the best estimator for the model\n",
    "# lr_tuned_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26de7e8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>Using the best parameters from the hyper tunning, we would build our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "722f6909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Tuned Training ACCURACY: 0.6379\n",
      "LR Tuned Testing  ACCURACY: 0.6974\n",
      "LR Tuned AUC Score        : 0.7441\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING a logistic regression model with tuned values\n",
    "lr_tuned = LogisticRegression(C            = 8.9,\n",
    "                              warm_start   = True,\n",
    "                              class_weight = 'balanced',\n",
    "                              solver       = 'newton-cg',\n",
    "                              max_iter     = 171,\n",
    "                              random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the model to the full dataset\n",
    "lr_tuned.fit(got_data, got_target) # this is ok because already tuned\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "lr_tuned_pred = lr_tuned.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('LR Tuned Training ACCURACY:', lr_tuned.score(x_train, y_train).round(4))\n",
    "print('LR Tuned Testing  ACCURACY:', lr_tuned.score(x_test, y_test).round(4))\n",
    "print('LR Tuned AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = lr_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "lr_tuned_train_score = lr_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "lr_tuned_test_score  = lr_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "lr_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                     y_score = lr_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832667d9",
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>We would unpack the confusion matrix to get individual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e41a1cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 42\n",
      "False Positives: 8\n",
      "False Negatives: 51\n",
      "True Positives : 94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "lr_tuned_tn, \\\n",
    "lr_tuned_fp, \\\n",
    "lr_tuned_fn, \\\n",
    "lr_tuned_tp = confusion_matrix(y_true = y_test, y_pred = lr_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {lr_tuned_tn}\n",
    "False Positives: {lr_tuned_fp}\n",
    "False Negatives: {lr_tuned_fn}\n",
    "True Positives : {lr_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f11fdf5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>Logging model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a5f3670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.7441</td>\n",
       "      <td>0.6379</td>\n",
       "      <td>0.6974</td>\n",
       "      <td>(42, 8, 51, 94)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Name  AUC Score  Training Accuracy  Testing Accuracy Confusion Matrix\n",
       "0   Tuned LR     0.7441             0.6379            0.6974  (42, 8, 51, 94)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "lr_train_acc = lr_tuned.score(x_train, y_train).round(4)\n",
    "lr_test_acc  = lr_tuned.score(x_test, y_test).round(4)\n",
    "lr_auc       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = lr_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Tuned LR',\n",
    "                           'Training Accuracy' : lr_train_acc,\n",
    "                           'Testing Accuracy'  : lr_test_acc,\n",
    "                           'AUC Score'         : lr_auc,\n",
    "                           'Confusion Matrix'  : (lr_tuned_tn,\n",
    "                                                  lr_tuned_fp,\n",
    "                                                  lr_tuned_fn,\n",
    "                                                  lr_tuned_tp)},\n",
    "                           ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dec817",
   "metadata": {},
   "source": [
    "<br><br><strong>Classification Trees</strong>\n",
    "\n",
    "<br>Using Classification Trees, we will create a classification model using hyper tuning to determine best parameters. \n",
    "<br> Then we would comment our the hyper tuning portion so our code runs faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98e1dd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # declaring a hyperparameter space\n",
    "# criterion_range = ['gini', 'entropy']\n",
    "# splitter_range  = ['best', 'random']\n",
    "# depth_range     = np.arange(1, 8, 1)\n",
    "# leaf_range      = np.arange(1, 100, 1)\n",
    "\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'criterion'        : criterion_range,\n",
    "#               'splitter'         : splitter_range,\n",
    "#               'max_depth'        : depth_range,\n",
    "#               'min_samples_leaf' : leaf_range}\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# tuned_tree = DecisionTreeClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# # RandomizedSearchCV object\n",
    "# tuned_tree_cv = RandomizedSearchCV(estimator             = tuned_tree,\n",
    "#                                    param_distributions   = param_grid,\n",
    "#                                    cv                    = 5,\n",
    "#                                    n_iter                = 1000,\n",
    "#                                    random_state          = 219,\n",
    "#                                    scoring = make_scorer(roc_auc_score,\n",
    "#                                              needs_threshold = False))\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# tuned_tree_cv.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "# # PREDICT step is not needed\n",
    "\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", tuned_tree_cv.best_params_)\n",
    "# print(\"Tuned Training AUC:\", tuned_tree_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178702a3",
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>Using the best parameters from the hyper tunning, we would build our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0199af25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7801\n",
      "Testing  ACCURACY: 0.8667\n",
      "AUC Score        : 0.799\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING a logistic regression model with tuned values\n",
    "tree_tuned = DecisionTreeClassifier(splitter         = 'best',\n",
    "                                    min_samples_leaf = 21,\n",
    "                                    max_depth        = 4,\n",
    "                                    criterion        = 'gini',\n",
    "                                    random_state     = 219)\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "tree_tuned_fit = tree_tuned.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "tree_tuned_pred = tree_tuned.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', tree_tuned.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_tuned.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "tree_tuned_train_score = tree_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "tree_tuned_test_score  = tree_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "tree_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                       y_score = tree_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c5ff94",
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>We would unpack the confusion matrix to get individual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4fe2105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 33\n",
      "False Positives: 17\n",
      "False Negatives: 9\n",
      "True Positives : 136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "tuned_tree_tn, \\\n",
    "tuned_tree_fp, \\\n",
    "tuned_tree_fn, \\\n",
    "tuned_tree_tp = confusion_matrix(y_true = y_test, y_pred = tree_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_tree_tn}\n",
    "False Positives: {tuned_tree_fp}\n",
    "False Negatives: {tuned_tree_fn}\n",
    "True Positives : {tuned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c4b9be",
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>Logging model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f18b86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.7441</td>\n",
       "      <td>0.6379</td>\n",
       "      <td>0.6974</td>\n",
       "      <td>(42, 8, 51, 94)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.7990</td>\n",
       "      <td>0.7801</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>(33, 17, 9, 136)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Name  AUC Score  Training Accuracy  Testing Accuracy  Confusion Matrix\n",
       "0    Tuned LR     0.7441             0.6379            0.6974   (42, 8, 51, 94)\n",
       "1  Tuned Tree     0.7990             0.7801            0.8667  (33, 17, 9, 136)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "tree_train_acc = tree_tuned.score(x_train, y_train).round(4)\n",
    "tree_test_acc  = tree_tuned.score(x_test, y_test).round(4)\n",
    "tree_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = tree_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Tuned Tree',\n",
    "                           'Training Accuracy' : tree_train_acc,\n",
    "                           'Testing Accuracy'  : tree_test_acc,\n",
    "                           'AUC Score'         : tree_auc,\n",
    "                           'Confusion Matrix'  : (tuned_tree_tn,\n",
    "                                                  tuned_tree_fp,\n",
    "                                                  tuned_tree_fn,\n",
    "                                                  tuned_tree_tp)},\n",
    "                           ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51081e81",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br><strong>Random Forest (Classification)</strong>\n",
    "\n",
    "<br>Using Random Forest, we will create a classification model using hyper tuning to determine best parameters. \n",
    "<br> Then we would comment our the hyper tuning portion so our code runs faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a6faddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8475\n",
      "Testing  ACCURACY: 0.8769\n",
      "AUC Score        : 0.7862\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a random forest model with default values\n",
    "rf_default = RandomForestClassifier(n_estimators     = 100,\n",
    "                                    criterion        = 'gini',\n",
    "                                    max_depth        = 8,\n",
    "                                    min_samples_leaf = 1,\n",
    "                                    bootstrap        = True,\n",
    "                                    warm_start       = False,\n",
    "                                    random_state     = 219)\n",
    "# FITTING the training data\n",
    "rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', rf_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', rf_default_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rf_default_fit_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90eda80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FITTING the training data\n",
    "# rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# # PREDICTING based on the testing set\n",
    "# rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# # declaring a hyperparameter space\n",
    "# estimator_range  = np.arange(100, 2000, 50)\n",
    "# leaf_range       = np.arange(1, 31, 5)\n",
    "# criterion_range  = ['gini', 'entropy']\n",
    "# bootstrap_range  = [True, False]\n",
    "# warm_start_range = [True, False]\n",
    "# max_depth_range  = np.arange(1, 8, 1)\n",
    "\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'n_estimators'     : estimator_range,\n",
    "#               'min_samples_leaf' : leaf_range,\n",
    "#               'criterion'        : criterion_range,\n",
    "#               'bootstrap'        : bootstrap_range,\n",
    "#               'max_depth'        : max_depth_range,\n",
    "#               'warm_start'       : warm_start_range}\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# forest_grid = RandomForestClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# # GridSearchCV object\n",
    "# forest_cv = RandomizedSearchCV(estimator           = forest_grid,\n",
    "#                                param_distributions = param_grid,\n",
    "#                                cv         = 5,\n",
    "#                                n_iter     = 1000,\n",
    "#                                n_jobs     = -4,\n",
    "#                                scoring    = make_scorer(roc_auc_score,\n",
    "#                                             needs_threshold = False))\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# forest_cv.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "# # PREDICT step is not needed\n",
    "\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", forest_cv.best_params_)\n",
    "# print(\"Tuned Training AUC:\", forest_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45463a2a",
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>Using the best parameters from the hyper tunning, we would build our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a63a630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest Tuned Training ACCURACY: 0.8264\n",
      "Forest Tuned Testing  ACCURACY: 0.9026\n",
      "Forest Tuned AUC Score        : 0.8166\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING with best_estimator\n",
    "forest_tuned = RandomForestClassifier(criterion        = 'entropy',\n",
    "                                      min_samples_leaf = 1,\n",
    "                                      n_estimators     = 600,\n",
    "                                      warm_start       = False,\n",
    "                                      max_depth        = 7,\n",
    "                                      bootstrap        = False,\n",
    "                                      random_state     = 219)\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "forest_tuned_fit = forest_tuned.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "forest_tuned_pred = forest_tuned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Forest Tuned Training ACCURACY:', forest_tuned.score(x_train, y_train).round(4))\n",
    "print('Forest Tuned Testing  ACCURACY:', forest_tuned.score(x_test, y_test).round(4))\n",
    "print('Forest Tuned AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                                       y_score = forest_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "forest_tuned_train_score = forest_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "forest_tuned_test_score  = forest_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "forest_tuned_auc = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = forest_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b934fd7",
   "metadata": {},
   "source": [
    "Function to examine results with a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "197c4575",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances(model, train, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = train.shape[1]\n",
    "    \n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('./analysis_images/Feature_Importance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4df0450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plotting feature importances\n",
    "# plot_feature_importances(forest_tuned_fit,\n",
    "#                          train = x_train,\n",
    "#                          export = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6ed6da",
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>We would unpack the confusion matrix to get individual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5eb1321d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 32\n",
      "False Positives: 18\n",
      "False Negatives: 1\n",
      "True Positives : 144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "tuned_rf_tn, \\\n",
    "tuned_rf_fp, \\\n",
    "tuned_rf_fn, \\\n",
    "tuned_rf_tp = confusion_matrix(y_true = y_test, y_pred = forest_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_rf_tn}\n",
    "False Positives: {tuned_rf_fp}\n",
    "False Negatives: {tuned_rf_fn}\n",
    "True Positives : {tuned_rf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5dab35",
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>Logging model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e32e004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.7441</td>\n",
       "      <td>0.6379</td>\n",
       "      <td>0.6974</td>\n",
       "      <td>(42, 8, 51, 94)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.7990</td>\n",
       "      <td>0.7801</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>(33, 17, 9, 136)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tuned Random Forest (Full)</td>\n",
       "      <td>0.8166</td>\n",
       "      <td>0.8264</td>\n",
       "      <td>0.9026</td>\n",
       "      <td>(32, 18, 1, 144)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model Name  AUC Score  Training Accuracy  Testing Accuracy  Confusion Matrix\n",
       "0                    Tuned LR     0.7441             0.6379            0.6974   (42, 8, 51, 94)\n",
       "1                  Tuned Tree     0.7990             0.7801            0.8667  (33, 17, 9, 136)\n",
       "2  Tuned Random Forest (Full)     0.8166             0.8264            0.9026  (32, 18, 1, 144)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "tuned_rf_train_acc = forest_tuned_fit.score(x_train, y_train).round(4)\n",
    "tuned_rf_test_acc  = forest_tuned_fit.score(x_test, y_test).round(4)\n",
    "tuned_rf_auc       = roc_auc_score(y_true  = y_test,\n",
    "                                   y_score = forest_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'         : 'Tuned Random Forest (Full)',\n",
    "                           'Training Accuracy'  : tuned_rf_train_acc,\n",
    "                           'Testing Accuracy'   : tuned_rf_test_acc,\n",
    "                           'AUC Score'          : tuned_rf_auc,\n",
    "                           'Confusion Matrix'   : (tuned_rf_tn,\n",
    "                                                   tuned_rf_fp,\n",
    "                                                   tuned_rf_fn,\n",
    "                                                   tuned_rf_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52e2492",
   "metadata": {},
   "source": [
    "<br><br><strong>Gradient Boosted Models (GBM)</strong>\n",
    "\n",
    "<br>Using Gradient Boosted Model, we will create a classification model using hyper tuning to determine best parameters. \n",
    "<br> Then we would comment our the hyper tuning portion so our code runs faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20804744",
   "metadata": {},
   "source": [
    "Gradient Boosted Models (GBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7dba977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # declaring a hyperparameter space\n",
    "# learn_range        = np.arange(0.1, 2.2, 0.5)\n",
    "# estimator_range    = np.arange(100, 501, 25)\n",
    "# depth_range        = np.arange(2, 8, 1)\n",
    "# warm_start_range   = [True, False]\n",
    "# loss_range               = ['deviance', 'exponential']\n",
    "# criterion_range          = ['friedman_mse', 'squared_error', 'mse', 'mae']\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'learning_rate' : learn_range,\n",
    "#               'max_depth'     : depth_range,\n",
    "#               'n_estimators'  : estimator_range,\n",
    "#               'loss'          : loss_range,\n",
    "#               'criterion'     : criterion_range,\n",
    "#               'warm_start'    : warm_start_range}\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# full_gbm_grid = GradientBoostingClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# # GridSearchCV object\n",
    "# full_gbm_cv = RandomizedSearchCV(estimator     = full_gbm_grid,\n",
    "#                            param_distributions = param_grid,\n",
    "#                            cv                  = 3,\n",
    "#                            n_iter              = 500,\n",
    "#                            n_jobs              = -4,\n",
    "#                            random_state        = 219,\n",
    "#                            scoring             = make_scorer(roc_auc_score,\n",
    "#                                                  needs_threshold = False))\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# full_gbm_cv.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "# # PREDICT step is not needed\n",
    "\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", full_gbm_cv.best_params_)\n",
    "# print(\"Tuned Training AUC:\", full_gbm_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a53c67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checking the best estimator for the model\n",
    "# full_gbm_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9fdf84",
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>Using the best parameters from the hyper tunning, we would build our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1c23baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8281\n",
      "Testing  ACCURACY: 0.8872\n",
      "AUC Score        : 0.8586\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING with best_estimator\n",
    "gbm_tuned = GradientBoostingClassifier(learning_rate = 2.1,\n",
    "                                       max_depth     = 4,\n",
    "                                       n_estimators  = 475,\n",
    "                                       warm_start    = False,\n",
    "                                       loss          = 'exponential',\n",
    "                                       criterion     = 'friedman_mse',\n",
    "                                       random_state  = 219)\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "gbm_tuned_fit = gbm_tuned.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "gbm_tuned_pred = gbm_tuned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', gbm_tuned_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', gbm_tuned_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = gbm_tuned_pred).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33837718",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>We would unpack the confusion matrix to get individual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "164bcfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 40\n",
      "False Positives: 10\n",
      "False Negatives: 12\n",
      "True Positives : 133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "gbm_tuned_tn, \\\n",
    "gbm_tuned_fp, \\\n",
    "gbm_tuned_fn, \\\n",
    "gbm_tuned_tp = confusion_matrix(y_true = y_test, y_pred = gbm_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_tuned_tn}\n",
    "False Positives: {gbm_tuned_fp}\n",
    "False Negatives: {gbm_tuned_fn}\n",
    "True Positives : {gbm_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f4f285",
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br>Logging model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf32909b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.7441</td>\n",
       "      <td>0.6379</td>\n",
       "      <td>0.6974</td>\n",
       "      <td>(42, 8, 51, 94)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.7990</td>\n",
       "      <td>0.7801</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>(33, 17, 9, 136)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tuned Random Forest (Full)</td>\n",
       "      <td>0.8166</td>\n",
       "      <td>0.8264</td>\n",
       "      <td>0.9026</td>\n",
       "      <td>(32, 18, 1, 144)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned GBM</td>\n",
       "      <td>0.8586</td>\n",
       "      <td>0.8281</td>\n",
       "      <td>0.8872</td>\n",
       "      <td>(40, 10, 12, 133)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model Name  AUC Score  Training Accuracy  Testing Accuracy   Confusion Matrix\n",
       "0                    Tuned LR     0.7441             0.6379            0.6974    (42, 8, 51, 94)\n",
       "1                  Tuned Tree     0.7990             0.7801            0.8667   (33, 17, 9, 136)\n",
       "2  Tuned Random Forest (Full)     0.8166             0.8264            0.9026   (32, 18, 1, 144)\n",
       "3                   Tuned GBM     0.8586             0.8281            0.8872  (40, 10, 12, 133)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "gbm_train_acc = gbm_tuned_fit.score(x_train, y_train).round(4)\n",
    "gbm_test_acc  = gbm_tuned_fit.score(x_test, y_test).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = gbm_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Tuned GBM',\n",
    "                          'Training Accuracy'  : gbm_train_acc,\n",
    "                          'Testing Accuracy'   : gbm_test_acc,\n",
    "                          'AUC Score'          : gbm_auc,\n",
    "                          'Confusion Matrix'   : (gbm_tuned_tn,\n",
    "                                                  gbm_tuned_fp,\n",
    "                                                  gbm_tuned_fn,\n",
    "                                                  gbm_tuned_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa22156",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><br><br><strong>Results</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b462dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Name                     Training Accuracy  Testing Accuracy  AUC Score  Confusion Matrix\n",
      "Logistic Regression             0.6379            0.6974            0.7441     (42, 8, 51, 94)\n",
      "Classification Tree             0.7801            0.8667            0.799      (33, 17, 9, 136)\n",
      "Random Forest                   0.8264            0.9026            0.8166     (32, 18, 1, 144)\n",
      "*Gradient Boosted Models (GBM)  0.8281            0.8872            0.8586     (40, 10, 12, 133)\n",
      "\n",
      "Final Model = *Gradient Boosted Models (GBM) \n"
     ]
    }
   ],
   "source": [
    "print (f'''\n",
    "Model Name                     Training Accuracy  Testing Accuracy  AUC Score  Confusion Matrix\n",
    "Logistic Regression             {lr_train_acc}            {lr_test_acc}            {lr_auc}     {(lr_tuned_tn, lr_tuned_fp, lr_tuned_fn, lr_tuned_tp)}\n",
    "Classification Tree             {tree_train_acc}            {tree_test_acc}            {tree_auc}      {(tuned_tree_tn, tuned_tree_fp, tuned_tree_fn, tuned_tree_tp)}\n",
    "Random Forest                   {tuned_rf_train_acc}            {tuned_rf_test_acc}            {tuned_rf_auc}     {(tuned_rf_tn, tuned_rf_fp, tuned_rf_fn, tuned_rf_tp)}\n",
    "*Gradient Boosted Models (GBM)  {gbm_train_acc}            {gbm_test_acc}            {gbm_auc}     {(gbm_tuned_tn,  gbm_tuned_fp,  gbm_tuned_fn,  gbm_tuned_tp)}\n",
    "\\nFinal Model = *Gradient Boosted Models (GBM) ''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
